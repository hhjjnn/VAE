{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.current_device()\n",
    "from torch.nn import Module\n",
    "from torch.nn import Linear\n",
    "from torch import tanh, sigmoid, relu\n",
    "from torch.nn.functional import mse_loss\n",
    "import numpy as np\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch import diag_embed\n",
    "from torch import prod\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 3\n",
    "encoder_hidden_size= 500\n",
    "z_size = 8\n",
    "n_sample = 4\n",
    "decoder_hidden_size = 500\n",
    "x = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim, n_sample, device=None):\n",
    "        super(encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.n_sample = n_sample\n",
    "        self.device = device\n",
    "        \n",
    "        self.hidden_layer = Linear(input_size, hidden_size)\n",
    "        self.output_mu = Linear(hidden_size, output_dim)\n",
    "        self.output_sigma = Linear(hidden_size, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input shape: batch * input_size\n",
    "        # hidden shape: batch * hidden_size\n",
    "        hidden = tanh(self.hidden_layer(x))\n",
    "        # mu shape: batch * output_dim\n",
    "        # sigma_sq shape: batch * output_dim\n",
    "        mu = self.output_mu(hidden)\n",
    "        sigma_sq = torch.exp(self.output_sigma(hidden))\n",
    "        \n",
    "        batch = x.shape[0]\n",
    "        # epsilon shape: batch, n_sample, 1\n",
    "        \n",
    "        epsilon = torch.randn(batch, self.n_sample).unsqueeze(-1).to(self.device)\n",
    "        # z shape: batch, n_sample, output_dim\n",
    "        z = epsilon * sigma_sq.unsqueeze(1) + mu.unsqueeze(1)\n",
    "        return (mu, sigma_sq, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder mu: tensor([[-0.6584,  0.3039,  0.0880, -0.0464,  0.2765, -0.3837,  0.2675,  0.2829],\n",
      "        [-0.6091,  0.3417,  0.0473, -0.2825,  0.2726, -0.4408, -0.1436,  0.5757],\n",
      "        [-0.6115,  0.3488,  0.0271, -0.3605,  0.2677, -0.4300, -0.3259,  0.7484]],\n",
      "       grad_fn=<AddmmBackward>) \n",
      " encoder sigma square: tensor([[2.2625, 1.1090, 0.9810, 1.4885, 0.8909, 1.3877, 1.5133, 1.9652],\n",
      "        [2.7670, 1.3089, 0.8597, 1.1280, 0.8037, 1.3614, 1.8750, 1.7751],\n",
      "        [2.6589, 1.4227, 0.7750, 1.0188, 0.8404, 1.3794, 1.8076, 1.6146]],\n",
      "       grad_fn=<ExpBackward>) \n",
      "z: tensor([[[-2.8471, -0.7690, -0.8611, -1.4864, -0.5854, -1.7262, -1.1964,\n",
      "          -1.6183],\n",
      "         [-2.7738, -0.7331, -0.8293, -1.4381, -0.5565, -1.6812, -1.1474,\n",
      "          -1.5546],\n",
      "         [-4.6086, -1.6325, -1.6248, -2.6452, -1.2790, -2.8066, -2.3746,\n",
      "          -3.1483],\n",
      "         [ 1.0161,  1.1247,  0.8140,  1.0552,  0.9359,  0.6433,  1.3875,\n",
      "           1.7374]],\n",
      "\n",
      "        [[-0.1094,  0.5781,  0.2026, -0.0788,  0.4178, -0.1950,  0.1950,\n",
      "           0.8963],\n",
      "         [-3.3911, -0.9743, -0.8171, -1.4166, -0.5354, -1.8096, -2.0288,\n",
      "          -1.2090],\n",
      "         [-1.8520, -0.2462, -0.3389, -0.7892, -0.0884, -1.0524, -0.9858,\n",
      "          -0.2216],\n",
      "         [ 1.3174,  1.2530,  0.6459,  0.5029,  0.8322,  0.5070,  1.1618,\n",
      "           1.8116]],\n",
      "\n",
      "        [[-1.6993, -0.2332, -0.2899, -0.7773, -0.0761, -0.9943, -1.0654,\n",
      "           0.0879],\n",
      "         [-2.2066, -0.5046, -0.4378, -0.9717, -0.2365, -1.2575, -1.4103,\n",
      "          -0.2202],\n",
      "         [ 0.3929,  0.8862,  0.3199,  0.0244,  0.5851,  0.0911,  0.3569,\n",
      "           1.3583],\n",
      "         [-0.4190,  0.4518,  0.0832, -0.2867,  0.3285, -0.3301, -0.1950,\n",
      "           0.8653]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test encoder\n",
    "Encoder = encoder(input_size=x_size, hidden_size=encoder_hidden_size,\n",
    "                  output_dim=z_size,n_sample=n_sample, device=None)\n",
    "\n",
    "encoder_mu,encoder_sigma_sq,z = Encoder(x)\n",
    "print(\"encoder mu:\",encoder_mu, \"\\n encoder sigma square:\",encoder_sigma_sq, \"\\nz:\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.hidden_layer = Linear(input_size, hidden_size)\n",
    "        self.output_layer = Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        # z shape: batch, n_sample, input_size\n",
    "        \n",
    "        # hidden shape: batch, n_sample, hidden_size\n",
    "        hidden = relu(self.hidden_layer(z))\n",
    "        # output shape: batch, n_sample, output_size\n",
    "        output = sigmoid(self.output_layer(hidden))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder = decoder(input_size=z_size, \n",
    "                  hidden_size=decoder_hidden_size,\n",
    "                  output_dim=x_size)\n",
    "output = Decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder output: tensor([[[0.5097, 0.6670, 0.5435],\n",
      "         [0.5102, 0.6620, 0.5422],\n",
      "         [0.5110, 0.7747, 0.5810],\n",
      "         [0.5739, 0.5221, 0.5678]],\n",
      "\n",
      "        [[0.5645, 0.5134, 0.4792],\n",
      "         [0.5485, 0.6409, 0.5290],\n",
      "         [0.5364, 0.5624, 0.5088],\n",
      "         [0.5638, 0.5353, 0.5514]],\n",
      "\n",
      "        [[0.5453, 0.5449, 0.5024],\n",
      "         [0.5481, 0.5679, 0.5088],\n",
      "         [0.5696, 0.5195, 0.4913],\n",
      "         [0.5695, 0.5164, 0.4756]]], grad_fn=<SigmoidBackward>) torch.Size([3, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"decoder output:\", output, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Module):\n",
    "    def __init__(self, x_size, encoder_hidden_size, decoder_hidden_size, z_size, n_sample, device=None):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_size = x_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.z_size = z_size\n",
    "        self.n_sample = n_sample\n",
    "        self.Encoder = encoder(input_size=x_size, hidden_size=encoder_hidden_size,\n",
    "                  output_dim=z_size,n_sample=n_sample, device=device)\n",
    "        self.Decoder = decoder(input_size=z_size, \n",
    "                  hidden_size=decoder_hidden_size,\n",
    "                  output_dim=x_size)\n",
    "    def forward(self, x):\n",
    "        encoder_mu, encoder_sigma_sq, z = self.Encoder(x)\n",
    "        output = self.Decoder(z)\n",
    "        \n",
    "        return (x, z, encoder_mu, encoder_sigma_sq, output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class preprocess_MNIST(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        super(preprocess_MNIST, self).__init__()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.underlying_tensor = MNIST(root=\"./\", download=False).train_data\n",
    "        else:\n",
    "            self.underlying_tensor = MNIST(root=\"./\", download=False).test_data\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.flatten(self.underlying_tensor[idx].float()/255.0)\n",
    "    def __len__(self):\n",
    "        return self.underlying_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hongm\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_MNIST()\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_loss(torch.nn.modules.loss._Loss):\n",
    "    def __init__(self, n_sample):\n",
    "        super(VAE_loss, self).__init__()\n",
    "        self.n_sample = n_sample\n",
    "    def forward(self, x, encoder_mu, encoder_sigma_sq, output):\n",
    "        original_dim = x.shape[1]\n",
    "        # x shape: batch, encoder input_size\n",
    "        # encoder_mu shape: batch, n_sample, encoder output dim\n",
    "        # encoder_sigma_sq shape: batch, n_sample, encoder output dim\n",
    "        # output shape: batch, n_sample, decoder output dim\n",
    "        assert n_sample == output.shape[1]\n",
    "        \n",
    "        encoder_loss = torch.sum(1 + torch.log(encoder_sigma_sq) - \\\n",
    "            encoder_sigma_sq - torch.pow(encoder_mu, 2)) / 2 \n",
    "        # decoder loss shape: batch, decoder output dim\n",
    "        decoder_loss = mse_loss(x, torch.sum(output, dim=1)/ n_sample) * original_dim\n",
    "        \n",
    "\n",
    "        return -(encoder_loss - decoder_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 784\n",
    "encoder_hidden_size= 500\n",
    "z_size = 10\n",
    "n_sample = 1\n",
    "decoder_hidden_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(x_size, encoder_hidden_size, decoder_hidden_size, z_size, n_sample, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(vae.parameters(), lr=0.0001)\n",
    "vae_loss = VAE_loss(n_sample).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(70.1156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(53.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(51.2921, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(49.4310, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(48.1970, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(46.4078, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(44.5553, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(42.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(39.0751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(36.5609, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(34.7975, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(33.3682, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(32.0156, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(30.9092, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(30.0824, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(29.4640, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(28.9448, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(28.4770, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(28.0563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(27.6813, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(27.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(27.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(26.8608, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(26.6597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(26.4807, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(26.3199, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(26.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(26.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.9255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.8188, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.7169, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.6230, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.4563, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.3052, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.1764, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(25.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(24.9979, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(24.9437, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(24.8992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(24.8438, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(24.8048, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(24.7560, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    loss_list = []\n",
    "    for x in dataloader:\n",
    "        vae.zero_grad()\n",
    "        vae(x.to(device=device))\n",
    "        z, log_prob, encoder_mu, encoder_sigma_sq, output = vae(x.to(device=device))\n",
    "        loss = vae_loss(x.to(device=device), encoder_mu, encoder_sigma_sq, output)\n",
    "        loss_list.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(sum(loss_list)/len(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hongm\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11084462780>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = MNIST(root=\"./\", download=False).test_data\n",
    "sample = test_data[10].numpy()\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_data[3].float().flatten()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_mu, encoder_sigma_sq, z = vae.Encoder(x.unsqueeze(0).to(device))\n",
    "\n",
    "#z, log_prob, encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = vae.Decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.3815e-04, 5.4841e-04, 5.5129e-04, 5.4479e-04, 5.5273e-04,\n",
       "          5.4691e-04, 5.4898e-04, 5.5509e-04, 5.4566e-04, 5.4413e-04,\n",
       "          5.3607e-04, 5.4049e-04, 5.3605e-04, 5.6592e-04, 5.5580e-04,\n",
       "          5.4538e-04, 5.2804e-04, 5.4487e-04, 5.3869e-04, 5.4797e-04,\n",
       "          5.3286e-04, 5.4304e-04, 5.5100e-04, 5.4307e-04, 5.3765e-04,\n",
       "          5.4727e-04, 5.4617e-04, 5.4291e-04, 5.4297e-04, 5.5584e-04,\n",
       "          5.4251e-04, 5.4223e-04, 5.4061e-04, 5.4972e-04, 5.7846e-04,\n",
       "          6.1233e-04, 6.6079e-04, 7.3783e-04, 9.4771e-04, 1.1057e-03,\n",
       "          1.1699e-03, 1.1431e-03, 1.2081e-03, 1.1679e-03, 1.2404e-03,\n",
       "          1.1032e-03, 8.5929e-04, 7.3762e-04, 6.9428e-04, 6.0738e-04,\n",
       "          5.7224e-04, 5.6743e-04, 5.5315e-04, 5.2797e-04, 5.4202e-04,\n",
       "          5.3698e-04, 5.3869e-04, 5.4070e-04, 5.5033e-04, 5.5259e-04,\n",
       "          5.6020e-04, 5.6646e-04, 6.7576e-04, 1.0014e-03, 1.6016e-03,\n",
       "          2.6835e-03, 3.8721e-03, 5.1736e-03, 7.1188e-03, 1.0350e-02,\n",
       "          1.2528e-02, 1.4916e-02, 1.5082e-02, 1.3289e-02, 1.1614e-02,\n",
       "          8.7321e-03, 4.8625e-03, 2.9557e-03, 1.7427e-03, 8.2817e-04,\n",
       "          6.3750e-04, 5.6166e-04, 5.4196e-04, 5.6024e-04, 5.4492e-04,\n",
       "          5.3033e-04, 5.5047e-04, 5.7011e-04, 5.6811e-04, 7.5741e-04,\n",
       "          1.3715e-03, 2.9573e-03, 4.8739e-03, 9.1898e-03, 1.4523e-02,\n",
       "          2.0111e-02, 2.7244e-02, 3.5838e-02, 4.2638e-02, 4.8261e-02,\n",
       "          4.9726e-02, 4.7338e-02, 3.9724e-02, 2.8849e-02, 1.7363e-02,\n",
       "          9.6548e-03, 4.3737e-03, 2.2894e-03, 1.1014e-03, 6.1634e-04,\n",
       "          5.4907e-04, 5.5179e-04, 5.4890e-04, 5.4516e-04, 5.6643e-04,\n",
       "          5.8502e-04, 7.8086e-04, 2.2031e-03, 4.3635e-03, 9.5658e-03,\n",
       "          1.9052e-02, 3.2233e-02, 5.0596e-02, 7.4473e-02, 1.0519e-01,\n",
       "          1.3563e-01, 1.5808e-01, 1.7417e-01, 1.7342e-01, 1.5591e-01,\n",
       "          1.2854e-01, 9.4473e-02, 6.1120e-02, 3.5876e-02, 1.9226e-02,\n",
       "          9.3918e-03, 3.7243e-03, 1.2926e-03, 6.2235e-04, 5.3521e-04,\n",
       "          5.4498e-04, 5.3695e-04, 5.6768e-04, 7.3986e-04, 2.0968e-03,\n",
       "          6.2673e-03, 1.4911e-02, 2.8694e-02, 5.0540e-02, 8.2918e-02,\n",
       "          1.2323e-01, 1.7141e-01, 2.2905e-01, 2.8592e-01, 3.3011e-01,\n",
       "          3.5623e-01, 3.5157e-01, 3.1751e-01, 2.6114e-01, 2.0031e-01,\n",
       "          1.4083e-01, 8.7801e-02, 4.9995e-02, 2.7717e-02, 1.2247e-02,\n",
       "          3.3639e-03, 1.0236e-03, 5.5566e-04, 5.4687e-04, 5.3150e-04,\n",
       "          6.0305e-04, 1.3388e-03, 4.6040e-03, 1.3930e-02, 3.0281e-02,\n",
       "          5.5129e-02, 9.2982e-02, 1.4601e-01, 2.0609e-01, 2.7435e-01,\n",
       "          3.4860e-01, 4.1796e-01, 4.6616e-01, 4.9203e-01, 4.7520e-01,\n",
       "          4.3038e-01, 3.7345e-01, 2.9562e-01, 2.1753e-01, 1.4057e-01,\n",
       "          8.5081e-02, 4.6912e-02, 2.2401e-02, 7.5015e-03, 2.0099e-03,\n",
       "          6.1583e-04, 5.4736e-04, 5.9475e-04, 8.7974e-04, 2.9829e-03,\n",
       "          9.0298e-03, 2.4594e-02, 5.0934e-02, 8.9387e-02, 1.4194e-01,\n",
       "          2.0848e-01, 2.8406e-01, 3.6473e-01, 4.3392e-01, 4.8959e-01,\n",
       "          5.1981e-01, 5.3289e-01, 5.2344e-01, 4.9187e-01, 4.3939e-01,\n",
       "          3.6752e-01, 2.7973e-01, 1.8789e-01, 1.1378e-01, 5.9984e-02,\n",
       "          2.8191e-02, 1.0235e-02, 2.6188e-03, 6.3055e-04, 5.6187e-04,\n",
       "          6.8575e-04, 1.8504e-03, 5.4668e-03, 1.5373e-02, 3.5313e-02,\n",
       "          6.8232e-02, 1.1670e-01, 1.8306e-01, 2.6296e-01, 3.5128e-01,\n",
       "          4.2109e-01, 4.6591e-01, 4.8477e-01, 4.8947e-01, 4.8269e-01,\n",
       "          4.8152e-01, 4.7728e-01, 4.4919e-01, 3.9461e-01, 3.0764e-01,\n",
       "          2.1286e-01, 1.2984e-01, 6.6224e-02, 2.8868e-02, 1.0511e-02,\n",
       "          2.4295e-03, 6.0429e-04, 5.7005e-04, 7.8932e-04, 2.7488e-03,\n",
       "          7.2844e-03, 1.8175e-02, 4.0398e-02, 7.8519e-02, 1.3557e-01,\n",
       "          2.1285e-01, 3.0503e-01, 3.8539e-01, 4.2893e-01, 4.3317e-01,\n",
       "          4.1505e-01, 4.0062e-01, 3.9447e-01, 4.0813e-01, 4.3195e-01,\n",
       "          4.2956e-01, 3.8234e-01, 3.0050e-01, 2.0855e-01, 1.2835e-01,\n",
       "          6.4877e-02, 2.5015e-02, 7.7439e-03, 1.9358e-03, 6.2797e-04,\n",
       "          5.6947e-04, 8.4149e-04, 2.7280e-03, 6.9153e-03, 1.7003e-02,\n",
       "          3.8933e-02, 7.9593e-02, 1.4386e-01, 2.3175e-01, 3.2470e-01,\n",
       "          3.9581e-01, 4.0612e-01, 3.7436e-01, 3.3528e-01, 3.2030e-01,\n",
       "          3.3512e-01, 3.7289e-01, 4.1013e-01, 4.1131e-01, 3.6628e-01,\n",
       "          2.7866e-01, 1.8733e-01, 1.1310e-01, 5.6647e-02, 1.8981e-02,\n",
       "          4.7440e-03, 1.3787e-03, 5.8504e-04, 5.5726e-04, 7.7981e-04,\n",
       "          2.2559e-03, 5.3483e-03, 1.4860e-02, 3.5893e-02, 8.0645e-02,\n",
       "          1.5539e-01, 2.4687e-01, 3.4601e-01, 3.8788e-01, 3.7398e-01,\n",
       "          3.2402e-01, 2.9901e-01, 3.0610e-01, 3.4226e-01, 3.8553e-01,\n",
       "          4.1855e-01, 4.0916e-01, 3.4665e-01, 2.5072e-01, 1.6242e-01,\n",
       "          9.8113e-02, 5.1456e-02, 1.6901e-02, 3.0725e-03, 9.6698e-04,\n",
       "          5.7392e-04, 5.5579e-04, 6.6504e-04, 1.4876e-03, 3.5311e-03,\n",
       "          1.1966e-02, 3.5728e-02, 8.8057e-02, 1.6742e-01, 2.6816e-01,\n",
       "          3.5735e-01, 3.8256e-01, 3.5693e-01, 3.2209e-01, 3.2317e-01,\n",
       "          3.5508e-01, 4.0581e-01, 4.4969e-01, 4.5878e-01, 4.1285e-01,\n",
       "          3.2702e-01, 2.3015e-01, 1.4717e-01, 9.2938e-02, 5.1958e-02,\n",
       "          1.7560e-02, 2.4387e-03, 7.8773e-04, 5.7379e-04, 5.5312e-04,\n",
       "          5.7676e-04, 9.3963e-04, 2.8617e-03, 1.1277e-02, 3.9826e-02,\n",
       "          9.7246e-02, 1.8254e-01, 2.8680e-01, 3.6106e-01, 3.7937e-01,\n",
       "          3.5426e-01, 3.4430e-01, 3.8254e-01, 4.4089e-01, 4.9105e-01,\n",
       "          5.1055e-01, 4.8910e-01, 4.1853e-01, 3.1356e-01, 2.1291e-01,\n",
       "          1.4232e-01, 9.4478e-02, 5.5690e-02, 2.0767e-02, 2.9316e-03,\n",
       "          7.9292e-04, 5.7242e-04, 5.5010e-04, 5.5814e-04, 6.8400e-04,\n",
       "          2.4359e-03, 1.1554e-02, 4.6068e-02, 1.0892e-01, 1.9463e-01,\n",
       "          2.8765e-01, 3.5172e-01, 3.6666e-01, 3.5991e-01, 3.7869e-01,\n",
       "          4.5124e-01, 5.1119e-01, 5.4323e-01, 5.2741e-01, 4.9385e-01,\n",
       "          4.1224e-01, 3.1095e-01, 2.1816e-01, 1.5142e-01, 1.0008e-01,\n",
       "          5.9795e-02, 2.3259e-02, 3.3716e-03, 8.2103e-04, 5.3979e-04,\n",
       "          5.3253e-04, 5.5559e-04, 6.7002e-04, 2.6417e-03, 1.3790e-02,\n",
       "          5.4471e-02, 1.1982e-01, 1.9717e-01, 2.7400e-01, 3.2514e-01,\n",
       "          3.5142e-01, 3.6246e-01, 4.1073e-01, 4.8083e-01, 5.2912e-01,\n",
       "          5.3459e-01, 5.0568e-01, 4.6746e-01, 3.9073e-01, 3.0697e-01,\n",
       "          2.2855e-01, 1.6176e-01, 1.0416e-01, 5.9411e-02, 2.4256e-02,\n",
       "          4.4483e-03, 1.0484e-03, 5.7231e-04, 5.4375e-04, 5.5287e-04,\n",
       "          7.6313e-04, 3.0100e-03, 1.7094e-02, 6.2785e-02, 1.2415e-01,\n",
       "          1.9464e-01, 2.5509e-01, 2.9792e-01, 3.2381e-01, 3.5105e-01,\n",
       "          3.9824e-01, 4.5620e-01, 4.9571e-01, 4.9210e-01, 4.7119e-01,\n",
       "          4.2850e-01, 3.6957e-01, 3.0282e-01, 2.3172e-01, 1.6529e-01,\n",
       "          1.0332e-01, 5.6375e-02, 2.3698e-02, 5.4399e-03, 1.2596e-03,\n",
       "          5.7857e-04, 5.3908e-04, 5.5295e-04, 9.0347e-04, 3.8954e-03,\n",
       "          2.2874e-02, 7.2939e-02, 1.3071e-01, 1.9068e-01, 2.3774e-01,\n",
       "          2.7180e-01, 2.9322e-01, 3.1445e-01, 3.4903e-01, 3.9970e-01,\n",
       "          4.4260e-01, 4.4842e-01, 4.3714e-01, 4.0291e-01, 3.5902e-01,\n",
       "          2.9850e-01, 2.3567e-01, 1.5979e-01, 9.5814e-02, 5.0344e-02,\n",
       "          2.1031e-02, 5.9879e-03, 1.2625e-03, 5.7378e-04, 5.5164e-04,\n",
       "          5.6621e-04, 1.1994e-03, 5.9762e-03, 2.9584e-02, 8.1717e-02,\n",
       "          1.4208e-01, 1.9495e-01, 2.3286e-01, 2.5778e-01, 2.7641e-01,\n",
       "          2.9617e-01, 3.2103e-01, 3.7366e-01, 4.1882e-01, 4.3876e-01,\n",
       "          4.3430e-01, 4.0716e-01, 3.6222e-01, 2.9668e-01, 2.2504e-01,\n",
       "          1.4929e-01, 8.7812e-02, 4.3900e-02, 1.8824e-02, 5.3344e-03,\n",
       "          1.0386e-03, 5.6876e-04, 5.3873e-04, 5.7336e-04, 1.7173e-03,\n",
       "          8.4182e-03, 3.4982e-02, 8.9902e-02, 1.4980e-01, 2.0866e-01,\n",
       "          2.4640e-01, 2.7881e-01, 3.0606e-01, 3.2224e-01, 3.5198e-01,\n",
       "          3.9689e-01, 4.4143e-01, 4.6429e-01, 4.5456e-01, 4.1414e-01,\n",
       "          3.5170e-01, 2.7971e-01, 2.0273e-01, 1.2861e-01, 7.2875e-02,\n",
       "          3.5668e-02, 1.4874e-02, 4.3174e-03, 1.0564e-03, 5.4258e-04,\n",
       "          5.4206e-04, 5.6898e-04, 1.9399e-03, 9.1879e-03, 3.4536e-02,\n",
       "          8.5292e-02, 1.5250e-01, 2.1590e-01, 2.7694e-01, 3.2428e-01,\n",
       "          3.5740e-01, 3.8712e-01, 4.2615e-01, 4.6642e-01, 4.9021e-01,\n",
       "          4.9277e-01, 4.5655e-01, 3.9551e-01, 3.2287e-01, 2.4960e-01,\n",
       "          1.6831e-01, 9.7630e-02, 5.1690e-02, 2.5914e-02, 1.1150e-02,\n",
       "          3.2193e-03, 9.1025e-04, 5.4753e-04, 5.4709e-04, 5.7036e-04,\n",
       "          1.6902e-03, 7.6702e-03, 2.6893e-02, 6.9012e-02, 1.3463e-01,\n",
       "          2.0717e-01, 2.8296e-01, 3.5190e-01, 4.0163e-01, 4.4884e-01,\n",
       "          4.8818e-01, 5.1307e-01, 5.1988e-01, 4.9169e-01, 4.3037e-01,\n",
       "          3.4633e-01, 2.6545e-01, 1.8714e-01, 1.1973e-01, 6.3724e-02,\n",
       "          3.3867e-02, 1.6541e-02, 7.1254e-03, 2.4993e-03, 7.2036e-04,\n",
       "          5.4592e-04, 5.3769e-04, 5.4355e-04, 1.2518e-03, 4.6081e-03,\n",
       "          1.6477e-02, 4.4400e-02, 9.5256e-02, 1.6370e-01, 2.4402e-01,\n",
       "          3.2811e-01, 3.9975e-01, 4.4686e-01, 4.7999e-01, 4.8835e-01,\n",
       "          4.6602e-01, 4.2430e-01, 3.4227e-01, 2.5574e-01, 1.7992e-01,\n",
       "          1.1331e-01, 6.8297e-02, 3.5619e-02, 1.9268e-02, 9.3132e-03,\n",
       "          3.6982e-03, 1.2750e-03, 5.8868e-04, 5.4843e-04, 5.3616e-04,\n",
       "          5.4537e-04, 7.3113e-04, 2.2106e-03, 7.2176e-03, 2.0833e-02,\n",
       "          5.0154e-02, 9.5861e-02, 1.6018e-01, 2.3683e-01, 3.0621e-01,\n",
       "          3.6104e-01, 3.9057e-01, 3.8588e-01, 3.5428e-01, 2.9908e-01,\n",
       "          2.2367e-01, 1.5116e-01, 9.5525e-02, 5.9464e-02, 3.3765e-02,\n",
       "          1.7848e-02, 9.2675e-03, 4.2000e-03, 1.8275e-03, 7.2234e-04,\n",
       "          5.7398e-04, 5.4973e-04, 5.3765e-04, 5.3856e-04, 5.8515e-04,\n",
       "          9.1114e-04, 2.6316e-03, 6.8796e-03, 1.7856e-02, 3.6982e-02,\n",
       "          6.5877e-02, 1.0452e-01, 1.4693e-01, 1.8172e-01, 1.9772e-01,\n",
       "          1.9636e-01, 1.7533e-01, 1.4479e-01, 1.0478e-01, 7.0983e-02,\n",
       "          4.5699e-02, 2.8064e-02, 1.6046e-02, 8.0160e-03, 3.8706e-03,\n",
       "          2.2157e-03, 8.5349e-04, 5.9361e-04, 5.4632e-04, 5.3237e-04,\n",
       "          5.3478e-04, 5.3636e-04, 5.5590e-04, 5.8839e-04, 9.8094e-04,\n",
       "          2.5054e-03, 6.0286e-03, 1.2994e-02, 2.4190e-02, 3.6941e-02,\n",
       "          5.1543e-02, 6.3666e-02, 6.8507e-02, 6.6887e-02, 6.3171e-02,\n",
       "          5.1573e-02, 3.8824e-02, 2.8994e-02, 1.9029e-02, 1.2489e-02,\n",
       "          6.9450e-03, 3.5469e-03, 2.0463e-03, 1.0199e-03, 6.4909e-04,\n",
       "          5.4722e-04, 5.3985e-04, 5.2807e-04, 5.4023e-04, 5.3824e-04,\n",
       "          5.5353e-04, 5.5223e-04, 6.3701e-04, 1.1168e-03, 2.7209e-03,\n",
       "          4.8905e-03, 9.2687e-03, 1.3561e-02, 1.8643e-02, 2.2798e-02,\n",
       "          2.5936e-02, 2.5518e-02, 2.3409e-02, 1.8432e-02, 1.3701e-02,\n",
       "          9.6638e-03, 6.4788e-03, 4.2446e-03, 2.8146e-03, 1.4553e-03,\n",
       "          7.6157e-04, 5.7137e-04, 5.5984e-04, 5.5399e-04, 5.3391e-04,\n",
       "          5.5206e-04, 5.4603e-04, 5.4233e-04, 5.3094e-04, 5.4882e-04,\n",
       "          5.3414e-04, 5.8465e-04, 6.5221e-04, 8.1799e-04, 9.7680e-04,\n",
       "          1.2090e-03, 1.9297e-03, 2.3606e-03, 2.6012e-03, 2.8738e-03,\n",
       "          3.2826e-03, 2.8750e-03, 2.5099e-03, 1.9453e-03, 1.2943e-03,\n",
       "          8.2006e-04, 6.7539e-04, 5.9435e-04, 5.6942e-04, 5.5492e-04,\n",
       "          5.4192e-04, 5.4980e-04, 5.4223e-04, 5.3537e-04]]], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (decoder_output * 255).reshape(28, 28).detach().cpu().to(torch.uint8).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1108440b5f8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
