{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.current_device()\n",
    "from torch.nn import Module\n",
    "from torch.nn import Linear\n",
    "from torch import tanh, sigmoid\n",
    "import numpy as np\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch import diag_embed\n",
    "from torch import prod\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import SGD\n",
    "from torch.optim import Adam\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 3\n",
    "encoder_hidden_size= 500\n",
    "z_size = 8\n",
    "n_sample = 4\n",
    "decoder_hidden_size = 500\n",
    "x = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim, n_sample, device=None):\n",
    "        super(encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.n_sample = n_sample\n",
    "        self.device = device\n",
    "        \n",
    "        self.hidden_layer = Linear(input_size, hidden_size)\n",
    "        self.output_mu = Linear(hidden_size, output_dim)\n",
    "        self.output_sigma = Linear(hidden_size, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # input shape: batch * input_size\n",
    "        # hidden shape: batch * hidden_size\n",
    "        hidden = tanh(self.hidden_layer(x))\n",
    "        # mu shape: batch * output_dim\n",
    "        # sigma_sq shape: batch * output_dim\n",
    "        mu = self.output_mu(hidden)\n",
    "        sigma_sq = torch.exp(self.output_sigma(hidden))\n",
    "        \n",
    "        batch = x.shape[0]\n",
    "        # epsilon shape: batch, n_sample, 1\n",
    "        \n",
    "        epsilon = torch.randn(batch, self.n_sample).unsqueeze(-1).to(self.device)\n",
    "        # z shape: batch, n_sample, output_dim\n",
    "        z = epsilon * sigma_sq.unsqueeze(1) + mu.unsqueeze(1)\n",
    "        return (mu, sigma_sq, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder mu: tensor([[ 1.2876e-02,  1.3260e-01,  8.8893e-02, -5.3834e-02,  5.5325e-02,\n",
      "          1.1162e-01, -1.0696e-01,  2.9720e-03,  9.4528e-02, -9.9075e-02],\n",
      "        [-1.8193e-01,  7.3331e-02, -3.1776e-02, -1.2325e-01, -1.1584e-01,\n",
      "         -2.9487e-02,  1.2328e-01,  2.0109e-02, -1.8197e-01,  5.7764e-03],\n",
      "        [ 1.7184e-02,  9.1804e-02, -3.6124e-04, -1.7259e-01, -1.3087e-01,\n",
      "          6.8525e-02,  1.5929e-01,  1.9951e-03, -8.6736e-02, -1.3353e-01],\n",
      "        [-1.0388e-01,  5.3329e-02, -2.1266e-02, -9.4224e-02,  8.0321e-02,\n",
      "         -1.6892e-02,  7.4990e-02, -7.4730e-02, -1.4986e-01, -9.1884e-02],\n",
      "        [-8.0176e-02,  1.2101e-01,  1.1087e-01, -1.3774e-01,  7.5564e-02,\n",
      "         -4.9728e-03,  1.2514e-01, -1.3668e-02, -7.7065e-02, -9.3935e-02],\n",
      "        [ 1.2806e-02,  4.2691e-02,  4.6489e-02, -1.3102e-01, -1.3698e-02,\n",
      "          7.9170e-02,  3.2081e-02, -9.8506e-03, -1.2422e-01, -8.4667e-02],\n",
      "        [-1.2213e-01,  1.7316e-01,  7.9375e-03, -1.8607e-02,  1.1029e-01,\n",
      "         -3.0668e-03,  1.3851e-02,  9.8739e-02, -6.2951e-02, -2.0110e-01],\n",
      "        [-2.4759e-02,  2.1274e-01,  1.5114e-02, -1.0159e-01, -5.3556e-02,\n",
      "         -4.3573e-02,  1.7395e-01,  2.1695e-01, -5.5196e-02,  8.6059e-02],\n",
      "        [-1.1466e-02,  1.1630e-01,  4.5803e-02, -1.7761e-01,  1.4217e-02,\n",
      "         -1.2114e-01,  1.5900e-01, -2.5822e-02, -5.8639e-02, -1.4759e-01],\n",
      "        [ 1.9443e-01,  4.4108e-02,  1.4068e-01, -9.1077e-02,  7.1353e-02,\n",
      "         -9.3591e-02, -1.3422e-01, -7.3800e-02, -8.4827e-03, -6.7025e-02],\n",
      "        [-3.7195e-03,  1.9915e-01,  2.3867e-02, -2.3865e-01, -1.3887e-01,\n",
      "          7.8366e-02,  1.4127e-01,  5.1505e-02,  1.0020e-03,  8.3374e-02],\n",
      "        [-6.2204e-02, -4.4786e-02, -4.4932e-03, -1.3035e-01, -1.8246e-01,\n",
      "          4.1260e-03,  1.2236e-01, -5.5780e-02, -6.6149e-02,  6.7322e-02],\n",
      "        [-1.4062e-01,  1.3356e-01, -3.5299e-02, -9.1598e-02,  9.1205e-02,\n",
      "          4.1168e-02, -5.8066e-03,  3.6007e-02,  2.5044e-02, -1.1982e-01],\n",
      "        [-1.5007e-01,  1.2677e-01,  2.6887e-02,  4.1920e-03, -3.6585e-02,\n",
      "          2.1207e-02,  4.4535e-02, -8.1851e-03, -6.1229e-02, -1.4071e-01],\n",
      "        [ 3.7065e-02,  8.7236e-02,  1.1716e-04, -1.1903e-01, -4.6532e-02,\n",
      "          9.7944e-02,  6.6281e-02,  4.4144e-02, -1.3921e-01, -1.4695e-01],\n",
      "        [ 7.1656e-04,  4.4889e-02, -4.4419e-02, -2.2295e-02,  3.4974e-03,\n",
      "         -3.5835e-02,  5.7344e-03,  6.0036e-02,  5.8209e-02, -7.3129e-02],\n",
      "        [ 5.4423e-02,  3.5563e-02,  4.8833e-02, -1.0376e-01,  4.8633e-02,\n",
      "          8.7937e-03,  8.8511e-02,  1.8117e-02, -3.7195e-02, -2.0264e-01],\n",
      "        [ 4.4834e-02,  3.1942e-02,  7.0383e-02, -3.5161e-02,  4.8091e-02,\n",
      "         -1.4776e-02, -2.8969e-03, -1.0310e-01, -1.4962e-01, -3.2501e-02],\n",
      "        [ 8.0283e-02,  1.7902e-01,  6.6247e-03, -1.0734e-01, -8.2463e-02,\n",
      "          9.8082e-02,  1.5603e-01, -2.2513e-02, -1.5776e-01,  1.2658e-01],\n",
      "        [ 1.5957e-01,  6.6625e-02,  1.3536e-01, -2.5051e-02,  5.8292e-02,\n",
      "         -3.2584e-02, -4.7095e-02, -1.3631e-01, -3.6632e-04, -1.0036e-01],\n",
      "        [-1.0265e-01,  5.3585e-02, -3.7135e-02, -1.5666e-01, -1.4617e-02,\n",
      "          5.8067e-02,  1.0848e-01, -6.0084e-02, -6.4513e-02, -6.2621e-02],\n",
      "        [-2.0776e-01,  1.0733e-01, -5.6199e-03, -9.8952e-02, -5.6740e-02,\n",
      "          4.6516e-02,  5.8608e-03,  4.1497e-03, -1.0610e-01, -1.0439e-01],\n",
      "        [-1.9476e-02,  1.1482e-01,  8.2984e-02, -1.2168e-01, -1.1185e-01,\n",
      "         -2.1740e-02,  1.0684e-01,  3.4555e-02, -5.1728e-02, -1.1161e-02],\n",
      "        [ 1.5024e-01, -5.2940e-02,  1.6041e-02, -5.9800e-02,  4.1315e-02,\n",
      "         -1.2511e-01,  7.4054e-03, -6.3120e-02, -7.9523e-02, -2.2077e-01],\n",
      "        [ 5.0982e-02,  1.2319e-02,  6.5230e-02, -1.0562e-01, -3.1660e-01,\n",
      "         -1.6642e-02,  2.6365e-01,  2.8064e-02,  1.1739e-02,  1.2069e-01],\n",
      "        [-3.4772e-02,  1.0744e-01,  7.1970e-02, -5.8228e-02, -7.7378e-02,\n",
      "         -1.1352e-01,  5.1403e-02, -1.8284e-02,  4.0937e-03, -9.6128e-02],\n",
      "        [-3.1373e-02, -1.0686e-01,  1.1472e-01, -8.1037e-02, -1.1360e-01,\n",
      "          7.8422e-02, -2.5800e-03, -5.1194e-02,  2.7945e-02, -9.8267e-02],\n",
      "        [ 3.5653e-02,  1.3862e-01,  4.6080e-02, -9.2200e-03, -2.7424e-02,\n",
      "          1.6721e-02,  1.2443e-02,  9.6275e-02,  1.7308e-02, -3.4463e-02],\n",
      "        [ 5.9390e-04,  8.4298e-02, -2.1070e-02, -9.1568e-02, -2.4492e-02,\n",
      "          1.1325e-02,  5.8740e-02,  4.8088e-02,  7.2711e-03,  3.3300e-02],\n",
      "        [ 2.3964e-01,  1.2684e-01,  5.4614e-02, -8.1971e-02, -7.5351e-02,\n",
      "         -5.2507e-02, -3.1081e-02, -4.8825e-02, -2.3520e-02, -6.6457e-02],\n",
      "        [-6.7275e-02,  1.4419e-01,  3.5854e-02, -1.3306e-01, -2.2421e-01,\n",
      "          5.9574e-03,  9.8569e-02,  9.0795e-02, -5.6280e-02, -9.9763e-04],\n",
      "        [-7.6583e-02,  3.2764e-02,  5.5626e-02, -1.3529e-02,  4.5116e-02,\n",
      "         -8.1161e-02, -5.5172e-02,  2.5386e-02,  1.2995e-01, -1.9035e-02],\n",
      "        [-4.1904e-02,  8.9771e-02,  4.9820e-02, -7.2676e-02,  1.1099e-01,\n",
      "         -2.0188e-02,  7.8722e-02, -4.0043e-02, -1.7817e-01, -8.0778e-02],\n",
      "        [-1.0136e-01,  6.9475e-02, -4.5136e-02, -9.0235e-02,  1.1412e-01,\n",
      "         -6.6520e-02,  1.0413e-01, -4.8201e-02, -6.2431e-02, -7.5023e-02],\n",
      "        [-7.7039e-02,  2.4673e-01, -4.3020e-02, -1.9896e-01, -6.4890e-02,\n",
      "          4.3058e-02,  2.1524e-01, -1.0383e-01, -9.4985e-02,  5.1395e-02],\n",
      "        [-9.9573e-02,  1.9734e-01, -6.5452e-02, -1.7548e-01, -1.7980e-01,\n",
      "          1.6752e-03,  1.3867e-01,  7.9635e-02, -5.4767e-02,  1.2059e-01],\n",
      "        [-6.3124e-02, -5.4573e-02,  4.1850e-02, -5.7409e-02,  2.3377e-02,\n",
      "          6.2008e-02,  1.9166e-02, -5.4124e-02, -2.5920e-02, -1.0211e-01],\n",
      "        [-8.3735e-03,  9.6013e-02, -1.9801e-02, -1.9597e-01, -1.4975e-01,\n",
      "          8.3265e-02,  1.9782e-01, -7.0870e-02, -9.1370e-02, -5.4111e-02],\n",
      "        [-6.7220e-02,  1.5457e-01, -1.3451e-01, -2.0236e-01,  1.0011e-01,\n",
      "          1.0827e-01,  1.4908e-01, -1.0452e-02, -1.4274e-01, -1.4510e-01],\n",
      "        [ 2.4176e-01,  2.0374e-01,  1.4221e-01, -3.3435e-02,  9.7997e-03,\n",
      "          1.1478e-01, -1.0069e-01, -5.6675e-02, -7.7072e-03, -6.4424e-02],\n",
      "        [-1.1411e-01,  5.1365e-02,  4.8291e-02, -1.8185e-01, -3.1606e-02,\n",
      "         -2.9083e-02,  9.1725e-02,  7.5811e-02, -1.9351e-02, -5.1867e-03],\n",
      "        [-5.4260e-02,  1.2707e-01,  6.0458e-02, -1.0581e-01, -8.4127e-02,\n",
      "         -1.0589e-01,  7.3233e-03, -7.3830e-02, -2.9068e-02, -1.3924e-01],\n",
      "        [-9.7478e-02,  1.2201e-01,  5.9858e-02, -9.2821e-02, -7.6790e-02,\n",
      "          9.3644e-02,  1.1035e-01,  6.6705e-02, -9.8716e-02, -1.6066e-01],\n",
      "        [-1.0882e-01,  7.0270e-02,  3.1067e-02, -4.2435e-02,  2.7172e-02,\n",
      "          7.5383e-03,  5.1894e-02, -5.4593e-04,  4.4632e-02, -1.4387e-01],\n",
      "        [ 9.7868e-02, -4.9295e-02,  1.8256e-01, -1.5403e-01, -1.2905e-01,\n",
      "         -6.6274e-02,  8.3326e-02,  1.6812e-02,  8.2216e-02,  3.2139e-02],\n",
      "        [-2.9754e-02,  7.2859e-02,  3.9872e-02, -6.9245e-02,  1.5616e-01,\n",
      "         -1.7718e-02, -9.2577e-02, -6.1096e-02,  4.8761e-02, -9.5736e-02],\n",
      "        [-1.0091e-02,  1.5822e-01,  1.7870e-02, -1.5881e-01, -2.3145e-02,\n",
      "         -4.6979e-02,  2.1774e-01,  1.5820e-01, -7.1114e-02,  9.0734e-02],\n",
      "        [ 2.7813e-02,  3.1233e-03,  1.5329e-02, -8.5982e-02, -1.4287e-02,\n",
      "         -1.4875e-02, -9.2347e-02, -2.2232e-02, -3.7864e-02, -6.1015e-02],\n",
      "        [-5.0533e-02,  1.1599e-01, -2.4318e-02, -1.7298e-01,  1.0471e-01,\n",
      "         -1.0135e-01,  6.7849e-02, -8.3771e-02, -1.0881e-01, -1.0912e-01],\n",
      "        [ 1.1581e-02,  2.7362e-02,  2.1839e-02, -8.6068e-02, -3.0404e-02,\n",
      "          8.0703e-02,  8.0967e-02,  2.9071e-02, -9.6831e-02, -5.7269e-02],\n",
      "        [-1.6556e-01,  1.9706e-01, -6.1200e-02,  1.8751e-02,  1.2735e-01,\n",
      "          4.7442e-02, -1.1850e-01, -1.6035e-02, -1.1237e-02, -1.1040e-01],\n",
      "        [ 8.7100e-02,  1.0196e-01,  4.8274e-02, -2.0280e-01, -1.0438e-01,\n",
      "          1.7175e-02,  1.5409e-02,  3.0436e-02, -7.7732e-02,  3.9301e-02],\n",
      "        [ 1.3518e-02,  7.1131e-02,  5.2331e-02, -1.7116e-01, -2.2559e-02,\n",
      "         -1.6890e-02,  1.0374e-02, -6.0743e-02,  1.0853e-03, -1.3839e-01],\n",
      "        [ 9.1293e-02,  5.5412e-02,  1.3144e-02, -1.0023e-01,  9.7110e-02,\n",
      "          4.2063e-02,  7.4889e-02, -1.3669e-01, -1.7691e-01, -1.7243e-01],\n",
      "        [ 1.2438e-01,  1.3662e-02,  1.4675e-01, -1.1897e-01, -1.7030e-01,\n",
      "          4.8215e-02, -1.3184e-01,  1.9118e-02,  4.0562e-03, -6.6338e-03],\n",
      "        [ 1.2196e-02,  4.8904e-03,  3.6793e-02, -1.2647e-01,  3.1467e-02,\n",
      "          6.1135e-03,  1.9586e-01, -5.8256e-02, -1.8960e-01, -9.5662e-02],\n",
      "        [-5.9646e-02,  8.5431e-02,  3.0100e-02, -4.1040e-02,  1.5860e-02,\n",
      "          5.2906e-02, -1.0764e-01,  6.2935e-02,  2.4091e-02, -1.0227e-01],\n",
      "        [ 9.2409e-02,  6.1711e-02,  1.1952e-01, -1.3926e-01, -6.6082e-02,\n",
      "          4.7410e-02,  8.2713e-02,  3.2958e-02, -1.3739e-01, -8.6712e-03],\n",
      "        [ 3.2143e-02,  4.6491e-02,  3.7447e-02, -1.8581e-01,  1.1141e-03,\n",
      "          1.0340e-01,  5.8216e-03, -1.4296e-02, -1.6553e-01, -1.1954e-01],\n",
      "        [-8.0236e-02,  1.1599e-01,  7.8096e-02, -6.3184e-02,  6.1597e-02,\n",
      "         -6.1517e-03,  6.1865e-02, -9.0792e-02, -1.1342e-01, -1.2317e-01],\n",
      "        [ 9.4264e-02, -7.2323e-02,  1.5568e-01, -9.9641e-02, -2.6340e-02,\n",
      "         -4.3448e-02,  1.2941e-02,  5.5362e-02, -6.9531e-02, -6.8613e-02],\n",
      "        [-7.5093e-03,  1.2633e-01,  4.4874e-02, -5.0426e-02,  1.1554e-01,\n",
      "         -8.8103e-02,  5.2403e-03, -5.2057e-02, -3.3507e-02, -7.2824e-02],\n",
      "        [ 8.0047e-02,  7.7295e-02,  1.6816e-02, -1.5935e-01, -1.6312e-01,\n",
      "          9.2344e-02, -3.9330e-02,  1.2158e-01,  9.0061e-04, -7.6686e-02],\n",
      "        [ 1.7268e-02,  1.4030e-01,  7.9254e-02, -2.8113e-02, -5.0516e-03,\n",
      "          2.8582e-02,  3.6462e-02,  4.2899e-02, -4.5370e-02, -1.5668e-01]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>) \n",
      " encoder sigma square: tensor([[1.0915, 1.0665, 1.0402, 0.8866, 1.0815, 0.9713, 1.0937, 1.0344, 1.0095,\n",
      "         1.0044],\n",
      "        [0.9087, 1.1957, 1.0370, 1.0657, 0.7174, 0.8055, 0.8255, 1.1513, 1.0689,\n",
      "         0.9238],\n",
      "        [0.8744, 0.9579, 1.0027, 0.8700, 1.0822, 0.8608, 1.0117, 1.1303, 1.0755,\n",
      "         0.8864],\n",
      "        [1.0461, 1.0651, 0.9983, 0.8341, 0.9889, 0.8214, 0.9913, 1.0384, 0.9177,\n",
      "         0.9545],\n",
      "        [0.9522, 1.1303, 1.1533, 0.8195, 0.8185, 0.7506, 0.9827, 1.1695, 0.9883,\n",
      "         0.9735],\n",
      "        [0.9052, 0.9449, 1.0744, 0.9164, 1.0402, 0.9219, 1.0027, 1.0450, 1.0680,\n",
      "         0.9384],\n",
      "        [1.0056, 1.1084, 1.0890, 0.7730, 1.1462, 0.7723, 0.9790, 1.0095, 0.9299,\n",
      "         0.8468],\n",
      "        [0.8121, 0.9488, 1.1087, 0.8013, 0.9189, 0.7944, 0.9652, 1.0000, 0.8885,\n",
      "         0.7653],\n",
      "        [1.1194, 1.1483, 1.0641, 0.8918, 1.0409, 1.0327, 1.0354, 0.8956, 0.9934,\n",
      "         0.9881],\n",
      "        [0.9847, 1.0186, 1.0868, 0.8934, 1.1036, 0.8914, 1.0748, 0.9882, 0.8291,\n",
      "         0.9109],\n",
      "        [0.8872, 1.0522, 1.0443, 0.9969, 0.9138, 0.7125, 0.8229, 1.1850, 1.0475,\n",
      "         0.9064],\n",
      "        [0.8232, 1.1429, 1.0822, 0.9050, 0.8330, 0.8630, 0.8492, 1.1510, 1.0060,\n",
      "         0.8680],\n",
      "        [1.0466, 1.0521, 0.9725, 0.8870, 0.9381, 0.8013, 1.0327, 1.0776, 0.9357,\n",
      "         0.9708],\n",
      "        [0.9572, 1.1009, 0.9885, 0.8525, 1.1453, 0.8173, 0.9693, 1.1806, 0.9740,\n",
      "         1.0721],\n",
      "        [0.8773, 0.9900, 1.0393, 0.9014, 1.0920, 0.8682, 1.0056, 1.1151, 1.0647,\n",
      "         0.8926],\n",
      "        [1.0157, 1.0358, 1.0531, 0.8973, 1.1610, 0.7853, 0.9125, 1.0182, 0.9653,\n",
      "         0.9904],\n",
      "        [0.9077, 1.0646, 1.0429, 0.9044, 1.0335, 0.7471, 0.9884, 0.9382, 0.9613,\n",
      "         0.9092],\n",
      "        [1.0145, 0.9767, 1.0399, 0.9158, 1.0713, 0.9010, 1.0849, 1.0060, 0.8954,\n",
      "         0.8528],\n",
      "        [0.8343, 0.9791, 1.1892, 1.0928, 0.8946, 0.8059, 0.8709, 1.3289, 1.1309,\n",
      "         0.8331],\n",
      "        [0.8939, 1.0061, 1.0040, 0.9954, 1.1635, 0.8992, 0.9999, 0.9791, 1.0242,\n",
      "         0.9338],\n",
      "        [0.9697, 1.0398, 0.9691, 0.9191, 1.0674, 0.7311, 0.9863, 1.0668, 0.9070,\n",
      "         0.9144],\n",
      "        [1.0845, 1.1141, 0.9231, 0.8508, 1.0355, 0.7841, 1.0145, 1.1239, 1.0018,\n",
      "         0.9842],\n",
      "        [0.8996, 1.0876, 1.1297, 0.8403, 0.9446, 0.7484, 0.8030, 1.2621, 1.0050,\n",
      "         0.8407],\n",
      "        [0.9790, 0.9466, 1.0197, 0.9280, 1.1404, 0.7971, 1.0120, 0.9302, 0.9806,\n",
      "         0.9631],\n",
      "        [0.8538, 1.0051, 0.9398, 0.8404, 1.0696, 0.9325, 0.9193, 1.0880, 0.9445,\n",
      "         0.6926],\n",
      "        [1.0081, 1.1881, 1.0157, 0.9212, 1.0680, 0.8498, 0.9464, 1.0236, 0.8728,\n",
      "         0.9403],\n",
      "        [0.9340, 1.1342, 0.9542, 0.8281, 1.0708, 0.9125, 1.0992, 1.0260, 0.9574,\n",
      "         1.0106],\n",
      "        [1.0767, 1.0290, 1.0766, 0.9408, 1.1209, 0.9595, 1.0025, 0.9861, 0.9899,\n",
      "         1.0280],\n",
      "        [1.0065, 1.0685, 0.9904, 0.9348, 0.9210, 0.8616, 1.0240, 1.0221, 1.1897,\n",
      "         0.9029],\n",
      "        [0.9630, 1.0831, 1.0634, 0.9745, 1.1442, 0.8707, 1.0314, 0.9573, 0.9376,\n",
      "         1.0636],\n",
      "        [0.8324, 1.0687, 0.9286, 0.8433, 0.8406, 0.8680, 0.7713, 1.1975, 0.9441,\n",
      "         0.7474],\n",
      "        [1.0781, 1.0186, 1.0940, 0.9333, 1.1290, 0.8529, 0.9838, 1.0157, 0.9323,\n",
      "         1.0091],\n",
      "        [1.0347, 1.0649, 1.0810, 0.8396, 0.9499, 0.9242, 0.9202, 0.9858, 0.8834,\n",
      "         0.8224],\n",
      "        [1.0505, 1.0764, 1.0287, 0.8975, 1.0094, 0.8294, 1.0149, 0.9606, 0.9653,\n",
      "         0.9853],\n",
      "        [0.8690, 1.1340, 0.9253, 1.0599, 0.8080, 0.7118, 0.8918, 1.1482, 1.0436,\n",
      "         1.0407],\n",
      "        [0.9387, 1.1355, 1.0682, 0.9167, 0.8238, 0.7003, 0.7927, 1.1120, 1.1106,\n",
      "         0.8690],\n",
      "        [0.9670, 1.0070, 0.9882, 0.9490, 1.0166, 0.8450, 0.9498, 1.1501, 1.0608,\n",
      "         0.9435],\n",
      "        [0.9084, 0.9547, 1.0645, 0.8459, 1.0108, 0.8652, 0.9716, 1.2340, 1.0376,\n",
      "         0.8431],\n",
      "        [0.8321, 1.0308, 0.9802, 0.8662, 1.0477, 0.8018, 0.9799, 1.1822, 1.1222,\n",
      "         0.8588],\n",
      "        [1.0750, 1.0358, 1.2264, 0.8604, 1.1676, 0.9613, 0.9823, 1.1374, 0.8343,\n",
      "         0.9337],\n",
      "        [0.9676, 1.0975, 1.2003, 0.9241, 0.8742, 0.8379, 1.0100, 0.9942, 0.9245,\n",
      "         0.8858],\n",
      "        [0.9482, 1.1000, 1.2157, 0.8513, 1.1904, 0.7505, 1.0117, 1.0869, 1.0859,\n",
      "         0.7653],\n",
      "        [0.9214, 1.1676, 0.9531, 0.8688, 0.9863, 0.8619, 0.9333, 0.9466, 0.9578,\n",
      "         0.9584],\n",
      "        [0.9946, 1.1243, 1.0376, 0.8716, 0.9421, 0.8989, 0.9542, 0.9749, 1.0474,\n",
      "         1.0466],\n",
      "        [0.8534, 1.2160, 1.1393, 0.8091, 1.0181, 0.8858, 0.8045, 1.0915, 1.0177,\n",
      "         0.8005],\n",
      "        [1.1475, 1.0040, 0.9621, 0.8509, 0.9621, 0.9187, 1.0523, 1.0165, 0.9626,\n",
      "         0.9354],\n",
      "        [0.8547, 0.9113, 0.9620, 0.7542, 0.8656, 0.8145, 1.0036, 0.9224, 0.8628,\n",
      "         0.7354],\n",
      "        [1.0253, 1.0247, 1.0642, 0.8460, 1.1049, 0.7564, 1.1283, 0.9693, 1.0036,\n",
      "         0.9879],\n",
      "        [0.9715, 0.9906, 1.0749, 0.8952, 1.0046, 0.9380, 0.9727, 1.0463, 1.0792,\n",
      "         0.9704],\n",
      "        [0.9105, 0.9729, 1.0006, 0.8925, 1.0293, 0.9459, 0.9403, 1.0337, 0.9584,\n",
      "         0.9037],\n",
      "        [1.0483, 0.9888, 0.9927, 0.8650, 1.0831, 0.8091, 1.0130, 0.8883, 0.9310,\n",
      "         0.9838],\n",
      "        [0.9320, 1.0221, 1.1801, 0.8621, 0.9350, 0.7652, 1.0323, 1.0161, 1.0209,\n",
      "         0.9559],\n",
      "        [1.0628, 1.0682, 1.0275, 0.8426, 1.1711, 1.0804, 0.9920, 0.9273, 0.9573,\n",
      "         0.9521],\n",
      "        [0.8323, 0.9919, 1.1126, 0.9288, 1.0231, 0.8250, 0.9934, 1.0590, 0.9615,\n",
      "         0.9347],\n",
      "        [1.0042, 1.1060, 1.1375, 0.7971, 1.1536, 0.9007, 0.8559, 1.1291, 0.9415,\n",
      "         0.9271],\n",
      "        [0.8882, 1.1627, 0.9785, 0.7571, 0.9381, 0.8420, 0.9586, 1.1177, 0.9290,\n",
      "         0.9210],\n",
      "        [0.9805, 1.0633, 1.0370, 0.9018, 1.0729, 0.9395, 1.1048, 0.9804, 0.9827,\n",
      "         0.9252],\n",
      "        [0.9039, 0.9937, 1.0807, 0.8483, 1.1261, 0.9575, 0.8714, 1.1001, 1.0413,\n",
      "         0.8767],\n",
      "        [0.9026, 0.9593, 1.0025, 0.8846, 1.0631, 0.9205, 1.0213, 1.1485, 1.0932,\n",
      "         0.9441],\n",
      "        [0.9053, 1.1219, 0.8959, 0.9452, 1.1884, 0.8849, 0.9996, 0.9753, 0.9246,\n",
      "         0.8745],\n",
      "        [0.9005, 1.0066, 0.9803, 0.8534, 1.0322, 0.8938, 0.9212, 0.8667, 0.8407,\n",
      "         0.8886],\n",
      "        [1.0556, 1.0331, 1.0896, 0.8432, 1.0011, 0.7913, 1.0853, 0.9566, 0.8529,\n",
      "         0.9650],\n",
      "        [0.9197, 1.1463, 1.0573, 0.7572, 1.0689, 0.8046, 0.9892, 0.9313, 0.9920,\n",
      "         0.9453],\n",
      "        [0.9477, 1.1007, 1.0521, 0.8110, 1.0898, 0.8083, 1.0201, 1.0330, 0.9033,\n",
      "         1.1040]], grad_fn=<ExpBackward>) \n",
      "z: tensor([[[-1.5629e-01, -3.2696e-02, -7.2327e-02, -1.9125e-01, -1.1229e-01,\n",
      "          -3.8920e-02, -2.7646e-01, -1.5734e-01, -6.1933e-02, -2.5475e-01]],\n",
      "\n",
      "        [[ 1.2095e-01,  4.7186e-01,  3.1387e-01,  2.3196e-01,  1.2326e-01,\n",
      "           2.3898e-01,  3.9843e-01,  4.0385e-01,  1.7432e-01,  3.1368e-01]],\n",
      "\n",
      "        [[ 1.3784e+00,  1.5830e+00,  1.5607e+00,  1.1818e+00,  1.5539e+00,\n",
      "           1.4086e+00,  1.7343e+00,  1.7616e+00,  1.5877e+00,  1.2465e+00]],\n",
      "\n",
      "        [[-7.6393e-01, -6.1870e-01, -6.5113e-01, -6.2047e-01, -5.4360e-01,\n",
      "          -5.3512e-01, -5.5049e-01, -7.2989e-01, -7.2890e-01, -6.9415e-01]],\n",
      "\n",
      "        [[ 7.2328e-01,  1.0747e+00,  1.0840e+00,  5.5374e-01,  7.6623e-01,\n",
      "           6.2834e-01,  9.5431e-01,  9.7313e-01,  7.5685e-01,  7.2745e-01]],\n",
      "\n",
      "        [[-5.5257e-01, -5.4745e-01, -6.2457e-01, -7.0336e-01, -6.6336e-01,\n",
      "          -4.9661e-01, -5.9420e-01, -6.6252e-01, -7.9126e-01, -6.7076e-01]],\n",
      "\n",
      "        [[ 6.3940e-01,  1.0125e+00,  8.3262e-01,  5.6681e-01,  9.7831e-01,\n",
      "           5.8177e-01,  7.5524e-01,  8.6320e-01,  6.4123e-01,  4.4014e-01]],\n",
      "\n",
      "        [[-1.0091e+00, -9.3733e-01, -1.3289e+00, -1.0729e+00, -1.1674e+00,\n",
      "          -1.0065e+00, -9.9602e-01, -9.9520e-01, -1.1322e+00, -8.4156e-01]],\n",
      "\n",
      "        [[ 6.1410e-02,  1.9106e-01,  1.1508e-01, -1.1955e-01,  8.1986e-02,\n",
      "          -5.3903e-02,  2.2641e-01,  3.2488e-02,  6.0362e-03, -8.3261e-02]],\n",
      "\n",
      "        [[-1.5346e-01, -3.1577e-01, -2.4329e-01, -4.0671e-01, -3.1855e-01,\n",
      "          -4.0852e-01, -5.1396e-01, -4.2292e-01, -3.0140e-01, -3.8885e-01]],\n",
      "\n",
      "        [[-8.5037e-01, -8.0500e-01, -9.7273e-01, -1.1900e+00, -1.0109e+00,\n",
      "          -6.0155e-01, -6.4401e-01, -1.0794e+00, -9.9864e-01, -7.8166e-01]],\n",
      "\n",
      "        [[-8.0199e-01, -1.0718e+00, -9.7704e-01, -9.4362e-01, -9.3104e-01,\n",
      "          -7.7144e-01, -6.4079e-01, -1.0901e+00, -9.7016e-01, -7.1266e-01]],\n",
      "\n",
      "        [[ 5.3722e-01,  8.1497e-01,  5.9453e-01,  4.8288e-01,  6.9877e-01,\n",
      "           5.6014e-01,  6.6302e-01,  7.3392e-01,  6.3104e-01,  5.0891e-01]],\n",
      "\n",
      "        [[-4.1762e-01, -1.8093e-01, -2.4942e-01, -2.3410e-01, -3.5671e-01,\n",
      "          -2.0724e-01, -2.2641e-01, -3.3817e-01, -3.3347e-01, -4.4038e-01]],\n",
      "\n",
      "        [[ 6.8329e-01,  8.1650e-01,  7.6571e-01,  5.4495e-01,  7.5787e-01,\n",
      "           7.3749e-01,  8.0701e-01,  8.6554e-01,  6.4505e-01,  5.1051e-01]],\n",
      "\n",
      "        [[-4.0152e-01, -3.6532e-01, -4.6148e-01, -3.7765e-01, -4.5628e-01,\n",
      "          -3.4683e-01, -3.5565e-01, -3.4317e-01, -3.2408e-01, -4.6535e-01]],\n",
      "\n",
      "        [[ 2.1210e-01,  2.2050e-01,  2.2999e-01,  5.3348e-02,  2.2816e-01,\n",
      "           1.3857e-01,  2.6021e-01,  1.8109e-01,  1.2979e-01, -4.4699e-02]],\n",
      "\n",
      "        [[-5.9316e-01, -5.8232e-01, -5.8362e-01, -6.1110e-01, -6.2565e-01,\n",
      "          -5.8140e-01, -6.8517e-01, -7.3579e-01, -7.1272e-01, -5.6880e-01]],\n",
      "\n",
      "        [[-8.7303e-01, -9.3969e-01, -1.3521e+00, -1.3559e+00, -1.1046e+00,\n",
      "          -8.2276e-01, -8.3910e-01, -1.5409e+00, -1.4499e+00, -8.2531e-01]],\n",
      "\n",
      "        [[-3.3393e-01, -4.8884e-01, -4.1894e-01, -5.7458e-01, -5.8402e-01,\n",
      "          -5.2898e-01, -5.9910e-01, -6.7685e-01, -5.6577e-01, -6.1590e-01]],\n",
      "\n",
      "        [[-1.5176e+00, -1.4636e+00, -1.4513e+00, -1.4978e+00, -1.5721e+00,\n",
      "          -1.0088e+00, -1.3307e+00, -1.6168e+00, -1.3880e+00, -1.3969e+00]],\n",
      "\n",
      "        [[ 7.4503e-01,  1.0861e+00,  8.0538e-01,  6.4853e-01,  8.5295e-01,\n",
      "           7.3535e-01,  8.9715e-01,  9.9153e-01,  7.7402e-01,  7.6023e-01]],\n",
      "\n",
      "        [[ 1.6344e-01,  3.3596e-01,  3.1269e-01,  4.9167e-02,  8.0212e-02,\n",
      "           1.3044e-01,  2.7011e-01,  2.9116e-01,  1.5261e-01,  1.5977e-01]],\n",
      "\n",
      "        [[-3.2400e-01, -5.1151e-01, -4.7792e-01, -5.0935e-01, -5.1112e-01,\n",
      "          -5.1123e-01, -4.8282e-01, -5.1375e-01, -5.5455e-01, -6.8734e-01]],\n",
      "\n",
      "        [[-1.4878e+00, -1.7991e+00, -1.6284e+00, -1.6202e+00, -2.2443e+00,\n",
      "          -1.6972e+00, -1.3931e+00, -1.9328e+00, -1.6904e+00, -1.1275e+00]],\n",
      "\n",
      "        [[ 1.8766e-02,  1.7053e-01,  1.2591e-01, -9.3035e-03, -2.0658e-02,\n",
      "          -6.8385e-02,  1.0167e-01,  3.6077e-02,  5.0445e-02, -4.6189e-02]],\n",
      "\n",
      "        [[ 5.5729e-01,  6.0793e-01,  7.1607e-01,  4.4083e-01,  5.6122e-01,\n",
      "           6.5353e-01,  6.9018e-01,  5.9543e-01,  6.3130e-01,  5.3862e-01]],\n",
      "\n",
      "        [[ 2.5107e+00,  2.5038e+00,  2.5207e+00,  2.1534e+00,  2.5491e+00,\n",
      "           2.2223e+00,  2.3168e+00,  2.3631e+00,  2.2927e+00,  2.3286e+00]],\n",
      "\n",
      "        [[-1.5760e+00, -1.5894e+00, -1.5724e+00, -1.5558e+00, -1.4671e+00,\n",
      "          -1.3383e+00, -1.5452e+00, -1.5529e+00, -1.8563e+00, -1.3809e+00]],\n",
      "\n",
      "        [[-1.9557e-01, -3.6268e-01, -4.2598e-01, -5.2242e-01, -5.9246e-01,\n",
      "          -4.4604e-01, -4.9722e-01, -4.8147e-01, -4.4728e-01, -5.4714e-01]],\n",
      "\n",
      "        [[-1.7678e+00, -2.0390e+00, -1.8612e+00, -1.8559e+00, -1.9416e+00,\n",
      "          -1.7674e+00, -1.4772e+00, -2.3556e+00, -1.9851e+00, -1.5280e+00]],\n",
      "\n",
      "        [[-8.5623e-01, -7.0383e-01, -7.3549e-01, -6.8846e-01, -7.7129e-01,\n",
      "          -6.9792e-01, -7.6664e-01, -7.0913e-01, -5.4428e-01, -7.4874e-01]],\n",
      "\n",
      "        [[-7.0227e-01, -5.8984e-01, -6.4007e-01, -6.0853e-01, -4.9522e-01,\n",
      "          -6.1003e-01, -5.0853e-01, -6.6917e-01, -7.4197e-01, -6.0566e-01]],\n",
      "\n",
      "        [[ 1.4025e+00,  1.6105e+00,  1.4276e+00,  1.1947e+00,  1.5592e+00,\n",
      "           1.1210e+00,  1.5571e+00,  1.3271e+00,  1.3195e+00,  1.3356e+00]],\n",
      "\n",
      "        [[-1.6180e+00, -1.7641e+00, -1.6837e+00, -2.0784e+00, -1.4976e+00,\n",
      "          -1.2190e+00, -1.3660e+00, -2.1398e+00, -1.9454e+00, -1.7940e+00]],\n",
      "\n",
      "        [[ 1.1278e-01,  4.5420e-01,  1.7619e-01,  3.1882e-02,  6.5519e-03,\n",
      "           1.6008e-01,  3.1799e-01,  3.3118e-01,  1.9645e-01,  3.1717e-01]],\n",
      "\n",
      "        [[ 1.0595e-01,  1.2150e-01,  2.1462e-01,  1.0851e-01,  2.0112e-01,\n",
      "           2.0975e-01,  1.8523e-01,  1.4696e-01,  1.5955e-01,  6.2854e-02]],\n",
      "\n",
      "        [[ 1.1538e+00,  1.3174e+00,  1.3422e+00,  8.8625e-01,  1.1434e+00,\n",
      "           1.1902e+00,  1.4409e+00,  1.5079e+00,  1.2362e+00,  1.0245e+00]],\n",
      "\n",
      "        [[-9.7866e-01, -9.7456e-01, -1.2082e+00, -1.1513e+00, -1.0475e+00,\n",
      "          -7.7000e-01, -9.2429e-01, -1.3055e+00, -1.3720e+00, -1.0858e+00]],\n",
      "\n",
      "        [[ 1.9177e+00,  1.8186e+00,  2.0543e+00,  1.3080e+00,  1.8302e+00,\n",
      "           1.6136e+00,  1.4307e+00,  1.7166e+00,  1.2930e+00,  1.3913e+00]],\n",
      "\n",
      "        [[-4.2182e-01, -2.9766e-01, -3.3341e-01, -4.7571e-01, -3.0960e-01,\n",
      "          -2.9553e-01, -2.2945e-01, -2.4036e-01, -3.1334e-01, -2.8689e-01]],\n",
      "\n",
      "        [[-1.1999e-01,  5.0818e-02, -2.3819e-02, -1.6482e-01, -1.6665e-01,\n",
      "          -1.5792e-01, -6.2810e-02, -1.4918e-01, -1.0435e-01, -1.9230e-01]],\n",
      "\n",
      "        [[ 3.1076e-01,  6.3929e-01,  4.8212e-01,  2.9210e-01,  3.6018e-01,\n",
      "           4.7553e-01,  5.2384e-01,  4.8608e-01,  3.2563e-01,  2.6395e-01]],\n",
      "\n",
      "        [[ 1.4332e-01,  3.5528e-01,  2.9409e-01,  1.7853e-01,  2.6601e-01,\n",
      "           2.3541e-01,  2.9378e-01,  2.4660e-01,  3.1015e-01,  1.2146e-01]],\n",
      "\n",
      "        [[ 3.4526e-01,  3.0320e-01,  5.1282e-01,  8.0516e-02,  1.6609e-01,\n",
      "           1.9052e-01,  3.1656e-01,  3.3323e-01,  3.7723e-01,  2.6419e-01]],\n",
      "\n",
      "        [[-1.0156e+00, -7.8969e-01, -7.8673e-01, -8.0031e-01, -6.7042e-01,\n",
      "          -8.0705e-01, -9.9668e-01, -9.3442e-01, -7.7828e-01, -8.9942e-01]],\n",
      "\n",
      "        [[ 5.0559e-01,  7.0801e-01,  5.9824e-01,  2.9623e-01,  4.9907e-01,\n",
      "           4.4444e-01,  8.2324e-01,  7.1467e-01,  4.4942e-01,  5.3443e-01]],\n",
      "\n",
      "        [[ 1.6335e+00,  1.6080e+00,  1.6820e+00,  1.2389e+00,  1.7161e+00,\n",
      "           1.1697e+00,  1.6748e+00,  1.4959e+00,  1.5338e+00,  1.4862e+00]],\n",
      "\n",
      "        [[ 4.2351e-01,  5.9939e-01,  5.0019e-01,  2.6384e-01,  5.9493e-01,\n",
      "           3.5638e-01,  5.4247e-01,  4.2677e-01,  4.1781e-01,  3.6440e-01]],\n",
      "\n",
      "        [[-1.0095e+00, -1.0638e+00, -1.1003e+00, -1.0870e+00, -1.1848e+00,\n",
      "          -9.8014e-01, -9.7362e-01, -1.1302e+00, -1.1717e+00, -1.0708e+00]],\n",
      "\n",
      "        [[-7.2996e-01, -3.3533e-01, -5.9568e-01, -4.4695e-01, -4.5578e-01,\n",
      "          -3.8819e-01, -6.6392e-01, -4.9431e-01, -5.1249e-01, -6.4007e-01]],\n",
      "\n",
      "        [[ 1.4968e+00,  1.6478e+00,  1.8331e+00,  1.1011e+00,  1.3097e+00,\n",
      "           1.1745e+00,  1.5767e+00,  1.5673e+00,  1.4663e+00,  1.4850e+00]],\n",
      "\n",
      "        [[-1.4994e+00, -1.4495e+00, -1.4103e+00, -1.3706e+00, -1.6897e+00,\n",
      "          -1.5549e+00, -1.4017e+00, -1.3808e+00, -1.3616e+00, -1.4937e+00]],\n",
      "\n",
      "        [[-1.2597e-01, -2.0352e-01, -2.7729e-01, -3.4269e-01, -1.6996e-01,\n",
      "          -1.7329e-01, -1.8444e-01, -4.1313e-01, -4.2791e-01, -4.1643e-01]],\n",
      "\n",
      "        [[ 1.1145e+00,  1.1041e+00,  1.2682e+00,  6.6694e-01,  9.6703e-01,\n",
      "           9.3625e-01,  7.1201e-01,  1.1323e+00,  9.3229e-01,  9.0740e-01]],\n",
      "\n",
      "        [[ 3.0586e-01,  3.8932e-01,  3.6031e-01,  1.2387e-01,  3.4163e-01,\n",
      "           2.8450e-01,  5.1281e-01,  3.1129e-01,  1.1754e-01,  2.0885e-01]],\n",
      "\n",
      "        [[ 1.5484e+00,  1.8292e+00,  1.7307e+00,  1.4379e+00,  1.7754e+00,\n",
      "           1.5936e+00,  1.7042e+00,  1.6708e+00,  1.6358e+00,  1.4150e+00]],\n",
      "\n",
      "        [[ 9.6287e-01,  1.0187e+00,  1.1603e+00,  6.7764e-01,  1.0184e+00,\n",
      "           9.6947e-01,  9.2192e-01,  1.0924e+00,  8.6536e-01,  8.3563e-01]],\n",
      "\n",
      "        [[-8.7636e-02, -8.0815e-02, -9.5593e-02, -3.0320e-01, -1.3997e-01,\n",
      "          -1.8762e-02, -1.2971e-01, -1.6671e-01, -3.1060e-01, -2.4483e-01]],\n",
      "\n",
      "        [[-6.0638e-01, -5.3608e-01, -4.4258e-01, -6.1255e-01, -6.2910e-01,\n",
      "          -5.2048e-01, -5.1910e-01, -6.5766e-01, -6.5078e-01, -6.3144e-01]],\n",
      "\n",
      "        [[ 1.5955e-01,  6.6090e-04,  2.2676e-01, -3.7770e-02,  4.8500e-02,\n",
      "           2.1354e-02,  7.9729e-02,  1.1820e-01, -8.5762e-03, -4.1871e-03]],\n",
      "\n",
      "        [[ 1.2090e+00,  1.3168e+00,  1.3005e+00,  9.2123e-01,  1.2693e+00,\n",
      "           8.2373e-01,  1.2559e+00,  1.0504e+00,  9.4941e-01,  1.0392e+00]],\n",
      "\n",
      "        [[ 7.9061e-01,  9.6296e-01,  8.3369e-01,  4.2566e-01,  6.6276e-01,\n",
      "           7.1403e-01,  7.2494e-01,  8.4117e-01,  7.6736e-01,  6.5366e-01]],\n",
      "\n",
      "        [[-2.7958e-01, -2.0446e-01, -2.5029e-01, -2.8214e-01, -3.4639e-01,\n",
      "          -2.2459e-01, -2.8305e-01, -2.8066e-01, -3.2831e-01, -5.0249e-01]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# test encoder\n",
    "Encoder = encoder(input_size=x_size, hidden_size=encoder_hidden_size,\n",
    "                  output_dim=z_size,n_sample=n_sample, device=None)\n",
    "\n",
    "encoder_mu,encoder_sigma_sq,z = Encoder(x)\n",
    "print(\"encoder mu:\",encoder_mu, \"\\n encoder sigma square:\",encoder_sigma_sq, \"\\nz:\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(decoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        \n",
    "        self.hidden_layer = Linear(input_size, hidden_size)\n",
    "        self.output_mu = Linear(hidden_size, output_dim)\n",
    "        self.output_sigma = Linear(hidden_size, output_dim)\n",
    "    def forward(self, z):\n",
    "        # z shape: batch, n_sample, input_size\n",
    "        \n",
    "        # hidden shape: batch, n_sample, hidden_size\n",
    "        hidden = tanh(self.hidden_layer(z))\n",
    "        # mu shape: batch, n_sample, output_dim\n",
    "        # sigma shape: batch, n_sample, output_dim\n",
    "        mu = self.output_mu(hidden)\n",
    "        sigma_sq = torch.exp(self.output_sigma(hidden))\n",
    "        \n",
    "        return (mu, sigma_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Decoder = decoder(input_size=z_size, \n",
    "                  hidden_size=decoder_hidden_size,\n",
    "                  output_dim=x_size)\n",
    "decoder_mu, decoder_sigma_sq = Decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder mu: tensor([[[ 0.3660,  0.1246,  0.1692,  ...,  0.0906, -0.0572,  0.0506]],\n",
      "\n",
      "        [[ 0.5025,  0.0716, -0.1124,  ...,  0.0012,  0.0483, -0.1076]],\n",
      "\n",
      "        [[ 0.7452, -0.1790, -0.4464,  ..., -0.0098,  0.2021, -0.1994]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.6410, -0.0525, -0.4579,  ..., -0.0463,  0.1745, -0.2355]],\n",
      "\n",
      "        [[ 0.6396, -0.0328, -0.2780,  ..., -0.0317,  0.0949, -0.1564]],\n",
      "\n",
      "        [[ 0.2971,  0.1269,  0.2288,  ...,  0.1071, -0.0416,  0.0674]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([64, 1, 784])\n",
      "decoder sigma_sq: tensor([[[1.0734, 1.0174, 0.9935,  ..., 0.8965, 1.3062, 0.8677]],\n",
      "\n",
      "        [[1.1002, 0.9781, 1.0047,  ..., 0.9131, 1.2927, 0.6851]],\n",
      "\n",
      "        [[1.1266, 0.7909, 0.9135,  ..., 1.2051, 1.0132, 0.4580]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.1025, 0.8605, 0.8269,  ..., 1.1574, 1.0283, 0.5148]],\n",
      "\n",
      "        [[1.1236, 0.8993, 0.8898,  ..., 1.0744, 1.1371, 0.5439]],\n",
      "\n",
      "        [[1.0176, 1.0172, 1.0183,  ..., 0.8314, 1.3646, 0.9661]]],\n",
      "       grad_fn=<ExpBackward>) torch.Size([64, 1, 784])\n"
     ]
    }
   ],
   "source": [
    "print(\"decoder mu:\", decoder_mu, decoder_mu.shape)\n",
    "print(\"decoder sigma_sq:\", decoder_sigma_sq, decoder_sigma_sq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Module):\n",
    "    def __init__(self, x_size, encoder_hidden_size, decoder_hidden_size, z_size, n_sample, device=None):\n",
    "        super(VAE, self).__init__()\n",
    "        self.x_size = x_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.z_size = z_size\n",
    "        self.n_sample = n_sample\n",
    "        self.Encoder = encoder(input_size=x_size, hidden_size=encoder_hidden_size,\n",
    "                  output_dim=z_size,n_sample=n_sample, device=device)\n",
    "        self.Decoder = decoder(input_size=z_size, \n",
    "                  hidden_size=decoder_hidden_size,\n",
    "                  output_dim=x_size)\n",
    "    def forward(self, x):\n",
    "        encoder_mu, encoder_sigma_sq, z = self.Encoder(x)\n",
    "        decoder_mu, decoder_sigma_sq = self.Decoder(z)\n",
    "        \n",
    "        return (x, z, encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class preprocess_MNIST(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        super(preprocess_MNIST, self).__init__()\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            self.underlying_tensor = MNIST(root=\"./\", download=False).train_data\n",
    "        else:\n",
    "            self.underlying_tensor = MNIST(root=\"./\", download=False).test_data\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.flatten(self.underlying_tensor[idx].float()/255.0)\n",
    "    def __len__(self):\n",
    "        return self.underlying_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hongm\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torchvision\\datasets\\mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "dataset = preprocess_MNIST()\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_loss(torch.nn.modules.loss._Loss):\n",
    "    def __init__(self, n_sample):\n",
    "        super(VAE_loss, self).__init__()\n",
    "        self.n_sample = n_sample\n",
    "    def forward(self, x, encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq):\n",
    "        # encoder_mu shape: batch, n_sample, encoder output dim\n",
    "        # encoder_sigma_sq shape: batch, n_sample, encoder output dim\n",
    "        # decoder_mu shape: batch, n_sample, decoder output dim\n",
    "        # decoder_sigma_sq shape: batch, n_sample, decoder output_dim\n",
    "        # log_prob shape: batch, n_sample\n",
    "        assert n_sample == decoder_mu.shape[1]\n",
    "        \n",
    "        encoder_loss = torch.sum(1 + torch.log(encoder_sigma_sq) - \\\n",
    "            encoder_sigma_sq - torch.pow(encoder_mu, 2)) / 2\n",
    "        # log_prob shape: batch, n_sample, output_dim\n",
    "        log_prob = -1 / 2 * (torch.log(decoder_sigma_sq) + \\\n",
    "            1/decoder_sigma_sq * torch.pow(x - decoder_mu, 2))\n",
    "        decoder_loss = torch.sum(log_prob) / self.n_sample\n",
    "        return -(encoder_loss + decoder_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = 784\n",
    "encoder_hidden_size= 500\n",
    "z_size = 10\n",
    "n_sample = 1\n",
    "decoder_hidden_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(x_size, encoder_hidden_size, decoder_hidden_size, z_size, n_sample, device=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(vae.parameters(), lr=0.0001)\n",
    "vae_loss = VAE_loss(n_sample).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.0544e+22, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(-5.0889e+22, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3fdb23d0c0a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mvae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_sigma_sq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_sigma_sq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_sigma_sq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_sigma_sq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-e3f969dfa6bf>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         encoder_loss = torch.sum(1 + torch.log(encoder_sigma_sq) - \\\n\u001b[1;32m---> 14\u001b[1;33m             encoder_sigma_sq - torch.pow(encoder_mu, 2)) / 2\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# log_prob shape: batch, n_sample, output_dim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         log_prob = -1 / 2 * (torch.log(decoder_sigma_sq) + \\\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    loss_list = []\n",
    "    for x in dataloader:\n",
    "        vae.zero_grad()\n",
    "        vae(x.to(device=device))\n",
    "        z, log_prob, encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq = vae(x.to(device=device))\n",
    "        loss = vae_loss(x.to(device=device), encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq)\n",
    "        loss_list.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(sum(loss_list)/len(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hongm\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\torchvision\\datasets\\mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242030bf320>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = MNIST(root=\"./\", download=False).test_data\n",
    "sample = test_data[10].numpy()\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_data[1].float().flatten()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_mu, encoder_sigma_sq, z = vae.Encoder(x.to(device))\n",
    "\n",
    "#z, log_prob, encoder_mu, encoder_sigma_sq, decoder_mu, decoder_sigma_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=500, out_features=784, bias=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.Decoder.output_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prob, decoder_mu, decoder_sigma_sq = vae.Decoder(encoder_mu, x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (decoder_mu * 255).reshape(28, 28).detach().cpu().to(torch.uint8).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2420bf65b70>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
